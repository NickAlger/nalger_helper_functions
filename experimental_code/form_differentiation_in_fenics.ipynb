{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taking the derivative of a form in fenics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we use the following form:\n",
    "$$a(m,u,v) := \\int_\\Omega e^m \\nabla u \\cdot \\nabla v dx.$$\n",
    "We will show three methods for taking the derivative of $a$ with respect to $m$ in the direction of a function $h$. That is, \n",
    "$$\\frac{da}{dm}h = \\lim_{s \\rightarrow 0}\\frac{a(m+sh,u,v) - a(m,u,v)}{s}.$$\n",
    "For notational convenience, we do not explicitly write the dependence of $\\frac{da}{dm}h$ on $m,u,v$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from fenics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = UnitSquareMesh(10,11)\n",
    "\n",
    "V = FunctionSpace(mesh, 'CG', 1)\n",
    "\n",
    "u = TrialFunction(V)\n",
    "v = TestFunction(V)\n",
    "m = Function(V)\n",
    "\n",
    "a = inner(exp(m) * grad(u), grad(v))*dx\n",
    "\n",
    "h = Function(V)\n",
    "h.vector()[:] = np.random.randn(V.dim())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1: finite differences\n",
    "We may approximate the derivative with the finite difference:\n",
    "$$\\frac{da}{dm}h \\approx \\frac{a(m+sh,u,v) - a(m,u,v)}{s}$$\n",
    "for some small but finite step size $s$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "A1 = assemble(a).array() \n",
    "\n",
    "s = 1e-6 # finite difference step size\n",
    "m.vector()[:] = m.vector() + s * h.vector()\n",
    "\n",
    "A2 = assemble(a).array()\n",
    "\n",
    "dA_finitediff = (A2 - A1)/s # Assembled derivative via finite differences\n",
    "\n",
    "m.vector()[:] = m.vector() - s * h.vector() # Reset m to it's original state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The command .array() in assemble(a).array() converts the sparse petsc matrix generated by the command assemble(a) into a dense numpy array.\n",
    "We do this for convenience here since numpy arrays are easier to work with than petsc matrices. But converting a sparse matrix to a dense matrix is highly computationally inefficient, so you should use the petsc matrices in real problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2: analytical formula\n",
    "From calculus, one can show that\n",
    "$$\\begin{aligned}\n",
    "\\frac{da}{dm}h &= \\frac{d}{dm}\\left(\\int_\\Omega e^m \\nabla u \\cdot \\nabla v dx\\right)h \\\\\n",
    "&= \\int_\\Omega h e^m \\nabla u \\cdot \\nabla v dx.\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step size= 1e-06 , error_analytic_vs_finitediff= 7.339890987128867e-07\n"
     ]
    }
   ],
   "source": [
    "da_dm_h_analytic = inner(h * exp(m) * grad(u), grad(v))*dx\n",
    "\n",
    "dA_analytic = assemble(da_dm_h_analytic).array() # Assembled derivative via analytical formula\n",
    "\n",
    "error_analytic_vs_finitediff = np.linalg.norm(dA_finitediff - dA_analytic)/np.linalg.norm(dA_finitediff)\n",
    "print('step size=', s, ', error_analytic_vs_finitediff=', error_analytic_vs_finitediff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 3: Automatic differentiation using fenics.derivative()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step size= 1e-06 , error_autodiff_vs_finitediff= 7.339890987128867e-07\n"
     ]
    }
   ],
   "source": [
    "da_dm_h_autodiff = derivative(a, m, h)\n",
    "\n",
    "dA_autodiff = assemble(da_dm_h_autodiff).array() # Assembled derivative via automatic differentiation\n",
    "\n",
    "error_autodiff_vs_finitediff = np.linalg.norm(dA_finitediff - dA_autodiff)/np.linalg.norm(dA_finitediff)\n",
    "print('step size=', s, ', error_autodiff_vs_finitediff=', error_autodiff_vs_finitediff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You should use Method 3 (fenics.derivative()) whenever possible\n",
    "Reasons:\n",
    "### Accuracy \n",
    " - Automatic differentiation is exact (to numerical precision). \n",
    " - Analytical formulas may not be exact, because differentiation and discretization do not always commute. However, note that differentiation and discretization do commute for Galerkin discretizations, such as the one used here, so the analytic formula is exact in this example. \n",
    " - Finite differences are not exact, owing to the finite step size. Choosing a good step size can be difficult.\n",
    "\n",
    "### Computational efficiency\n",
    " - Automatic differentiation procedure will typically result in more computationally efficient code than implementation of an analytic formula that you derived by-hand. People have dedicated their careers, gotten PhD's, written books, etc, on the subject of optimizing the computational graph in automatic differentiation. \n",
    " - Assembly of the derivative form generated by automatic differentiation is typically faster and uses less memory than assembly of the original form at two different locations, as is done in finite differences.\n",
    " \n",
    "### Human efficiency\n",
    " - To use the analytical formula approach, you must spend a lot of time and effort doing calculus on pencil and paper, typing formulas, and checking your work/debugging. In contrast, for automatic differentiation you just call one function, and you know that it is going to be correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ufl import replace\n",
    "\n",
    "u = TrialFunction(V)\n",
    "v = TestFunction(V)\n",
    "u_fct = Function(V)\n",
    "a = inner(grad(u), grad(v))*dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u= v_1\n",
      "v= v_0\n",
      "u_fct= f_27\n"
     ]
    }
   ],
   "source": [
    "print('u=', u)\n",
    "print('v=', v)\n",
    "print('u_fct=', u_fct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functions in a\n",
      "TestFunctions and TrialFunctionst in a=\n",
      "v_0\n",
      "v_1\n"
     ]
    }
   ],
   "source": [
    "print('Functions in a')\n",
    "for coeff in a.coefficients():\n",
    "    print(coeff)\n",
    "    \n",
    "print('TestFunctions and TrialFunctionst in a=')\n",
    "for arg in a.arguments():\n",
    "    print(arg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2 = replace(a, {u:u_fct})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functions in a2\n",
      "f_27\n",
      "TestFunctions and TrialFunctionst in a2=\n",
      "v_0\n"
     ]
    }
   ],
   "source": [
    "print('Functions in a2')\n",
    "for coeff in a2.coefficients():\n",
    "    print(coeff)\n",
    "    \n",
    "print('TestFunctions and TrialFunctionst in a2=')\n",
    "for arg in a2.arguments():\n",
    "    print(arg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
